import React, { useEffect, useRef, useState } from 'react';
import * as faceapi from 'face-api.js';
import './App.css';

function App() {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const imageRef = useRef(null);
  const fileInputRef = useRef(null);

  const [modelsLoaded, setModelsLoaded] = useState(false);
  const [captureMode, setCaptureMode] = useState({
    detection: false,
    landmarks: false,
    expressions: false,
    ageGender: false
  });
  const [mediaType, setMediaType] = useState('webcam'); 
  const [uploadedImage, setUploadedImage] = useState(null);

  const loadModels = () => {
    Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
      faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
      faceapi.nets.faceRecognitionNet.loadFromUri('/models'),
      faceapi.nets.faceExpressionNet.loadFromUri('/models'),
      faceapi.nets.ageGenderNet.loadFromUri('/models')
    ]).then(() => {
      console.log("Models loaded successfully");
      setModelsLoaded(true);
    }).catch((err) => {
      console.error("Error loading models:", err);
    });
  };

  const startWebcam = () => {
    navigator.mediaDevices.getUserMedia({
      video: { width: 940, height: 720 }
    }).then((stream) => {
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.play();
      }
    }).catch((err) => {
      console.error("Error accessing webcam:", err);
    });
  };

  const handleImageUpload = (event) => {
    const file = event.target.files[0];
    if (file) {
      const reader = new FileReader();
      reader.onload = (e) => {
        const img = new Image();
        img.onload = () => {
          setUploadedImage(img);
          setMediaType('image');
        };
        img.src = e.target.result;
      };
      reader.readAsDataURL(file);
    }
  };

  const toggleFeature = (feature) => {
    setCaptureMode(prev => ({
      ...prev,
      [feature]: !prev[feature]
    }));
  };

  const detectFaces = () => {
    const canvas = canvasRef.current;
    if (!canvas || !modelsLoaded) return;

    let sourceElement;
    let displaySize;

    if (mediaType === 'webcam') {
      const video = videoRef.current;
      if (!video) return;
      
      canvas.width = video.videoWidth || 940;
      canvas.height = video.videoHeight || 720;
      
      sourceElement = video;
      displaySize = { width: canvas.width, height: canvas.height };
    } else {
      const img = imageRef.current;
      if (!img) return;
      
      canvas.width = img.width;
      canvas.height = img.height;
      
      sourceElement = img;
      displaySize = { width: img.width, height: img.height };
    }

    const ctx = canvas.getContext('2d');
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    const detectAndDraw = async () => {
      try {
        const detections = await faceapi
          .detectAllFaces(
            sourceElement, 
            new faceapi.TinyFaceDetectorOptions({ 
              inputSize: 416, 
              scoreThreshold: 0.5 
            })
          )
          .withFaceLandmarks()
          .withFaceExpressions()
          .withAgeAndGender();

        const resizedDetections = faceapi.resizeResults(detections, displaySize);

        // Conditional drawing based on selected modes
        if (captureMode.detection) {
          faceapi.draw.drawDetections(canvas, resizedDetections);
        }

        if (captureMode.landmarks) {
          faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
        }

        if (captureMode.expressions) {
          faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
        }

        if (captureMode.ageGender) {
          resizedDetections.forEach(detection => {
            const box = detection.detection.box;
            ctx.fillStyle = 'white';
            ctx.font = '16px Arial';
            ctx.fillText(
              `Age: ${Math.round(detection.age)} | ${detection.gender}`, 
              box.x, 
              box.y - 10
            );
          });
        }
      } catch (err) {
        console.error("Face detection error:", err);
      }
    };

    detectAndDraw();
  };

  useEffect(() => {
    loadModels();
    startWebcam();
  }, []);

  useEffect(() => {
    if (Object.values(captureMode).some(mode => mode)) {
      const intervalId = setInterval(detectFaces, 500);
      return () => clearInterval(intervalId);
    }
  }, [captureMode, modelsLoaded, mediaType, uploadedImage]);

  return (
    <div className="container" style={{ 
      position: 'relative', 
      width: "100dvw", 
      height: 900,
      textAlign: 'center',
      display: 'flex',
      flexDirection: 'column',
      alignItems: 'center',
      justifyContent: 'center',
      
    }}>
      {/* Media Type Selector */}
      <div style={{ 
        display: 'flex', 
        justifyContent: 'center', 
        marginBottom: '20px' 
      }}>
        <button 
          onClick={() => setMediaType('webcam')}
          style={{ 
            margin: '0 10px', 
            backgroundColor: mediaType === 'webcam' ? 'green' : 'gray',
            color: 'white',
            padding: '10px',
            border: 'none',
            borderRadius: '5px'
          }}
        >
          Webcam
        </button>
        <input 
          type="file" 
          ref={fileInputRef}
          onChange={handleImageUpload}
          accept="image/*"
          style={{ display: 'none' }}
        />
        <button 
          onClick={() => fileInputRef.current.click()}
          style={{ 
            margin: '0 10px', 
            backgroundColor: mediaType === 'image' ? 'green' : 'gray',
            color: 'white',
            padding: '10px',
            border: 'none',
            borderRadius: '5px'
          }}
        >
          Upload Image
        </button>
      </div>

      {/* Feature Toggle Buttons */}
      <div style={{ 
        display: 'flex', 
        justifyContent: 'center', 
        marginBottom: '20px' 
      }}>
        <button 
          onClick={() => toggleFeature('detection')}
          style={{ 
            margin: '0 10px', 
            backgroundColor: captureMode.detection ? 'green' : 'gray',
            color: 'white',
            padding: '10px',
            border: 'none',
            borderRadius: '5px'
          }}
        >
          {captureMode.detection ? 'Disable' : 'Show'} Face Detection
        </button>

        <button 
          onClick={() => toggleFeature('landmarks')}
          style={{ 
            margin: '0 10px', 
            backgroundColor: captureMode.landmarks ? 'green' : 'gray',
            color: 'white',
            padding: '10px',
            border: 'none',
            borderRadius: '5px'
          }}
        >
          {captureMode.landmarks ? 'Disable' : 'Show'} Facial Landmarks
        </button>

        <button 
          onClick={() => toggleFeature('expressions')}
          style={{ 
            margin: '0 10px', 
            backgroundColor: captureMode.expressions ? 'green' : 'gray',
            color: 'white',
            padding: '10px',
            border: 'none',
            borderRadius: '5px'
          }}
        >
          {captureMode.expressions ? 'Disable' : 'Show'} Face Expressions
        </button>

        <button 
          onClick={() => toggleFeature('ageGender')}
          style={{ 
            margin: '0 10px', 
            backgroundColor: captureMode.ageGender ? 'green' : 'gray',
            color: 'white',
            padding: '10px',
            border: 'none',
            borderRadius: '5px'
          }}
        >
          {captureMode.ageGender ? 'Disable' : 'Show'} Age & Gender
        </button>
      </div>

      {/* Media Display */}
      {mediaType === 'webcam' ? (
        <video 
          ref={videoRef} 
          width="940" 
          height="720" 
          // style={{ 
          //   // position: 'absolute', 
          //   // top: 120, 
          //   // left: 0 
          // }}
          autoPlay 
          muted 
          playsInline
        />
      ) : (
        <img 
          ref={imageRef}
          src={uploadedImage?.src}
          alt="Uploaded"
          style={{ 
            // position: 'absolute', 
            // top: 120, 
            // left: 0,
            maxWidth: '940px',
            maxHeight: '720px',
            objectFit: 'contain'
          }}
        />
      )}

      <canvas 
        ref={canvasRef} 
        style={{ 
          position: 'absolute', 
          top: 120, 
          left: 400, 
          zIndex: 10 
        }}
      />
    </div>
  );
}

export default App;